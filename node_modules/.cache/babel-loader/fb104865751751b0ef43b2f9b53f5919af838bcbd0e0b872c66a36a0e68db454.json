{"ast":null,"code":"import { z } from \"zod\";\nimport { interpolateFString, PromptTemplate } from \"@langchain/core/prompts\";\nimport { MultiRouteChain } from \"./multi_route.js\";\nimport { STRUCTURED_MULTI_PROMPT_ROUTER_TEMPLATE } from \"./multi_prompt_prompt.js\";\nimport { LLMChain } from \"../../chains/llm_chain.js\";\nimport { LLMRouterChain } from \"./llm_router.js\";\nimport { ConversationChain } from \"../../chains/conversation.js\";\nimport { zipEntries } from \"./utils.js\";\nimport { RouterOutputParser } from \"../../output_parsers/router.js\";\n/**\n * A class that represents a multi-prompt chain in the LangChain\n * framework. It extends the MultiRouteChain class and provides additional\n * functionality specific to multi-prompt chains.\n * @example\n * ```typescript\n * const multiPromptChain = MultiPromptChain.fromLLMAndPrompts(new ChatOpenAI(), {\n *   promptNames: [\"physics\", \"math\", \"history\"],\n *   promptDescriptions: [\n *     \"Good for answering questions about physics\",\n *     \"Good for answering math questions\",\n *     \"Good for answering questions about history\",\n *   ],\n *   promptTemplates: [\n *     `You are a very smart physics professor. Here is a question:\\n{input}\\n`,\n *     `You are a very good mathematician. Here is a question:\\n{input}\\n`,\n *     `You are a very smart history professor. Here is a question:\\n{input}\\n`,\n *   ],\n * });\n * const result = await multiPromptChain.call({\n *   input: \"What is the speed of light?\",\n * });\n * ```\n */\nexport class MultiPromptChain extends MultiRouteChain {\n  /**\n   * @deprecated Use `fromLLMAndPrompts` instead\n   */\n  static fromPrompts(llm, promptNames, promptDescriptions, promptTemplates, defaultChain, options) {\n    return MultiPromptChain.fromLLMAndPrompts(llm, {\n      promptNames,\n      promptDescriptions,\n      promptTemplates,\n      defaultChain,\n      multiRouteChainOpts: options\n    });\n  }\n  /**\n   * A static method that creates an instance of MultiPromptChain from a\n   * BaseLanguageModel and a set of prompts. It takes in optional parameters\n   * for the default chain and additional options.\n   * @param llm A BaseLanguageModel instance.\n   * @param promptNames An array of prompt names.\n   * @param promptDescriptions An array of prompt descriptions.\n   * @param promptTemplates An array of prompt templates.\n   * @param defaultChain An optional BaseChain instance to be used as the default chain.\n   * @param llmChainOpts Optional parameters for the LLMChainInput, excluding 'llm' and 'prompt'.\n   * @param conversationChainOpts Optional parameters for the LLMChainInput, excluding 'llm' and 'outputKey'.\n   * @param multiRouteChainOpts Optional parameters for the MultiRouteChainInput, excluding 'defaultChain'.\n   * @returns An instance of MultiPromptChain.\n   */\n  static fromLLMAndPrompts(llm, {\n    promptNames,\n    promptDescriptions,\n    promptTemplates,\n    defaultChain,\n    llmChainOpts,\n    conversationChainOpts,\n    multiRouteChainOpts\n  }) {\n    const destinations = zipEntries(promptNames, promptDescriptions).map(([name, desc]) => `${name}: ${desc}`);\n    const structuredOutputParserSchema = z.object({\n      destination: z.string().optional().describe('name of the question answering system to use or \"DEFAULT\"'),\n      next_inputs: z.object({\n        input: z.string().describe(\"a potentially modified version of the original input\")\n      }).describe(\"input to be fed to the next model\")\n    });\n    const outputParser = new RouterOutputParser(structuredOutputParserSchema);\n    const destinationsStr = destinations.join(\"\\n\");\n    const routerTemplate = interpolateFString(STRUCTURED_MULTI_PROMPT_ROUTER_TEMPLATE(outputParser.getFormatInstructions({\n      interpolationDepth: 4\n    })), {\n      destinations: destinationsStr\n    });\n    const routerPrompt = new PromptTemplate({\n      template: routerTemplate,\n      inputVariables: [\"input\"],\n      outputParser\n    });\n    const routerChain = LLMRouterChain.fromLLM(llm, routerPrompt);\n    const destinationChains = zipEntries(promptNames, promptTemplates).reduce((acc, [name, template]) => {\n      let myPrompt;\n      if (typeof template === \"object\") {\n        myPrompt = template;\n      } else if (typeof template === \"string\") {\n        myPrompt = new PromptTemplate({\n          template: template,\n          inputVariables: [\"input\"]\n        });\n      } else {\n        throw new Error(\"Invalid prompt template\");\n      }\n      acc[name] = new LLMChain({\n        ...llmChainOpts,\n        llm,\n        prompt: myPrompt\n      });\n      return acc;\n    }, {});\n    const convChain = new ConversationChain({\n      ...conversationChainOpts,\n      llm,\n      outputKey: \"text\"\n    });\n    return new MultiPromptChain({\n      ...multiRouteChainOpts,\n      routerChain,\n      destinationChains,\n      defaultChain: defaultChain ?? convChain\n    });\n  }\n  _chainType() {\n    return \"multi_prompt_chain\";\n  }\n}","map":{"version":3,"names":["z","interpolateFString","PromptTemplate","MultiRouteChain","STRUCTURED_MULTI_PROMPT_ROUTER_TEMPLATE","LLMChain","LLMRouterChain","ConversationChain","zipEntries","RouterOutputParser","MultiPromptChain","fromPrompts","llm","promptNames","promptDescriptions","promptTemplates","defaultChain","options","fromLLMAndPrompts","multiRouteChainOpts","llmChainOpts","conversationChainOpts","destinations","map","name","desc","structuredOutputParserSchema","object","destination","string","optional","describe","next_inputs","input","outputParser","destinationsStr","join","routerTemplate","getFormatInstructions","interpolationDepth","routerPrompt","template","inputVariables","routerChain","fromLLM","destinationChains","reduce","acc","myPrompt","Error","prompt","convChain","outputKey","_chainType"],"sources":["/Users/youngchen/Downloads/cs224g-triage/node_modules/langchain/dist/chains/router/multi_prompt.js"],"sourcesContent":["import { z } from \"zod\";\nimport { interpolateFString, PromptTemplate } from \"@langchain/core/prompts\";\nimport { MultiRouteChain } from \"./multi_route.js\";\nimport { STRUCTURED_MULTI_PROMPT_ROUTER_TEMPLATE } from \"./multi_prompt_prompt.js\";\nimport { LLMChain } from \"../../chains/llm_chain.js\";\nimport { LLMRouterChain } from \"./llm_router.js\";\nimport { ConversationChain } from \"../../chains/conversation.js\";\nimport { zipEntries } from \"./utils.js\";\nimport { RouterOutputParser } from \"../../output_parsers/router.js\";\n/**\n * A class that represents a multi-prompt chain in the LangChain\n * framework. It extends the MultiRouteChain class and provides additional\n * functionality specific to multi-prompt chains.\n * @example\n * ```typescript\n * const multiPromptChain = MultiPromptChain.fromLLMAndPrompts(new ChatOpenAI(), {\n *   promptNames: [\"physics\", \"math\", \"history\"],\n *   promptDescriptions: [\n *     \"Good for answering questions about physics\",\n *     \"Good for answering math questions\",\n *     \"Good for answering questions about history\",\n *   ],\n *   promptTemplates: [\n *     `You are a very smart physics professor. Here is a question:\\n{input}\\n`,\n *     `You are a very good mathematician. Here is a question:\\n{input}\\n`,\n *     `You are a very smart history professor. Here is a question:\\n{input}\\n`,\n *   ],\n * });\n * const result = await multiPromptChain.call({\n *   input: \"What is the speed of light?\",\n * });\n * ```\n */\nexport class MultiPromptChain extends MultiRouteChain {\n    /**\n     * @deprecated Use `fromLLMAndPrompts` instead\n     */\n    static fromPrompts(llm, promptNames, promptDescriptions, promptTemplates, defaultChain, options) {\n        return MultiPromptChain.fromLLMAndPrompts(llm, {\n            promptNames,\n            promptDescriptions,\n            promptTemplates,\n            defaultChain,\n            multiRouteChainOpts: options,\n        });\n    }\n    /**\n     * A static method that creates an instance of MultiPromptChain from a\n     * BaseLanguageModel and a set of prompts. It takes in optional parameters\n     * for the default chain and additional options.\n     * @param llm A BaseLanguageModel instance.\n     * @param promptNames An array of prompt names.\n     * @param promptDescriptions An array of prompt descriptions.\n     * @param promptTemplates An array of prompt templates.\n     * @param defaultChain An optional BaseChain instance to be used as the default chain.\n     * @param llmChainOpts Optional parameters for the LLMChainInput, excluding 'llm' and 'prompt'.\n     * @param conversationChainOpts Optional parameters for the LLMChainInput, excluding 'llm' and 'outputKey'.\n     * @param multiRouteChainOpts Optional parameters for the MultiRouteChainInput, excluding 'defaultChain'.\n     * @returns An instance of MultiPromptChain.\n     */\n    static fromLLMAndPrompts(llm, { promptNames, promptDescriptions, promptTemplates, defaultChain, llmChainOpts, conversationChainOpts, multiRouteChainOpts, }) {\n        const destinations = zipEntries(promptNames, promptDescriptions).map(([name, desc]) => `${name}: ${desc}`);\n        const structuredOutputParserSchema = z.object({\n            destination: z\n                .string()\n                .optional()\n                .describe('name of the question answering system to use or \"DEFAULT\"'),\n            next_inputs: z\n                .object({\n                input: z\n                    .string()\n                    .describe(\"a potentially modified version of the original input\"),\n            })\n                .describe(\"input to be fed to the next model\"),\n        });\n        const outputParser = new RouterOutputParser(structuredOutputParserSchema);\n        const destinationsStr = destinations.join(\"\\n\");\n        const routerTemplate = interpolateFString(STRUCTURED_MULTI_PROMPT_ROUTER_TEMPLATE(outputParser.getFormatInstructions({ interpolationDepth: 4 })), {\n            destinations: destinationsStr,\n        });\n        const routerPrompt = new PromptTemplate({\n            template: routerTemplate,\n            inputVariables: [\"input\"],\n            outputParser,\n        });\n        const routerChain = LLMRouterChain.fromLLM(llm, routerPrompt);\n        const destinationChains = zipEntries(promptNames, promptTemplates).reduce((acc, [name, template]) => {\n            let myPrompt;\n            if (typeof template === \"object\") {\n                myPrompt = template;\n            }\n            else if (typeof template === \"string\") {\n                myPrompt = new PromptTemplate({\n                    template: template,\n                    inputVariables: [\"input\"],\n                });\n            }\n            else {\n                throw new Error(\"Invalid prompt template\");\n            }\n            acc[name] = new LLMChain({\n                ...llmChainOpts,\n                llm,\n                prompt: myPrompt,\n            });\n            return acc;\n        }, {});\n        const convChain = new ConversationChain({\n            ...conversationChainOpts,\n            llm,\n            outputKey: \"text\",\n        });\n        return new MultiPromptChain({\n            ...multiRouteChainOpts,\n            routerChain,\n            destinationChains,\n            defaultChain: defaultChain ?? convChain,\n        });\n    }\n    _chainType() {\n        return \"multi_prompt_chain\";\n    }\n}\n"],"mappings":"AAAA,SAASA,CAAC,QAAQ,KAAK;AACvB,SAASC,kBAAkB,EAAEC,cAAc,QAAQ,yBAAyB;AAC5E,SAASC,eAAe,QAAQ,kBAAkB;AAClD,SAASC,uCAAuC,QAAQ,0BAA0B;AAClF,SAASC,QAAQ,QAAQ,2BAA2B;AACpD,SAASC,cAAc,QAAQ,iBAAiB;AAChD,SAASC,iBAAiB,QAAQ,8BAA8B;AAChE,SAASC,UAAU,QAAQ,YAAY;AACvC,SAASC,kBAAkB,QAAQ,gCAAgC;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMC,gBAAgB,SAASP,eAAe,CAAC;EAClD;AACJ;AACA;EACI,OAAOQ,WAAWA,CAACC,GAAG,EAAEC,WAAW,EAAEC,kBAAkB,EAAEC,eAAe,EAAEC,YAAY,EAAEC,OAAO,EAAE;IAC7F,OAAOP,gBAAgB,CAACQ,iBAAiB,CAACN,GAAG,EAAE;MAC3CC,WAAW;MACXC,kBAAkB;MAClBC,eAAe;MACfC,YAAY;MACZG,mBAAmB,EAAEF;IACzB,CAAC,CAAC;EACN;EACA;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACI,OAAOC,iBAAiBA,CAACN,GAAG,EAAE;IAAEC,WAAW;IAAEC,kBAAkB;IAAEC,eAAe;IAAEC,YAAY;IAAEI,YAAY;IAAEC,qBAAqB;IAAEF;EAAqB,CAAC,EAAE;IACzJ,MAAMG,YAAY,GAAGd,UAAU,CAACK,WAAW,EAAEC,kBAAkB,CAAC,CAACS,GAAG,CAAC,CAAC,CAACC,IAAI,EAAEC,IAAI,CAAC,KAAK,GAAGD,IAAI,KAAKC,IAAI,EAAE,CAAC;IAC1G,MAAMC,4BAA4B,GAAG1B,CAAC,CAAC2B,MAAM,CAAC;MAC1CC,WAAW,EAAE5B,CAAC,CACT6B,MAAM,CAAC,CAAC,CACRC,QAAQ,CAAC,CAAC,CACVC,QAAQ,CAAC,2DAA2D,CAAC;MAC1EC,WAAW,EAAEhC,CAAC,CACT2B,MAAM,CAAC;QACRM,KAAK,EAAEjC,CAAC,CACH6B,MAAM,CAAC,CAAC,CACRE,QAAQ,CAAC,sDAAsD;MACxE,CAAC,CAAC,CACGA,QAAQ,CAAC,mCAAmC;IACrD,CAAC,CAAC;IACF,MAAMG,YAAY,GAAG,IAAIzB,kBAAkB,CAACiB,4BAA4B,CAAC;IACzE,MAAMS,eAAe,GAAGb,YAAY,CAACc,IAAI,CAAC,IAAI,CAAC;IAC/C,MAAMC,cAAc,GAAGpC,kBAAkB,CAACG,uCAAuC,CAAC8B,YAAY,CAACI,qBAAqB,CAAC;MAAEC,kBAAkB,EAAE;IAAE,CAAC,CAAC,CAAC,EAAE;MAC9IjB,YAAY,EAAEa;IAClB,CAAC,CAAC;IACF,MAAMK,YAAY,GAAG,IAAItC,cAAc,CAAC;MACpCuC,QAAQ,EAAEJ,cAAc;MACxBK,cAAc,EAAE,CAAC,OAAO,CAAC;MACzBR;IACJ,CAAC,CAAC;IACF,MAAMS,WAAW,GAAGrC,cAAc,CAACsC,OAAO,CAAChC,GAAG,EAAE4B,YAAY,CAAC;IAC7D,MAAMK,iBAAiB,GAAGrC,UAAU,CAACK,WAAW,EAAEE,eAAe,CAAC,CAAC+B,MAAM,CAAC,CAACC,GAAG,EAAE,CAACvB,IAAI,EAAEiB,QAAQ,CAAC,KAAK;MACjG,IAAIO,QAAQ;MACZ,IAAI,OAAOP,QAAQ,KAAK,QAAQ,EAAE;QAC9BO,QAAQ,GAAGP,QAAQ;MACvB,CAAC,MACI,IAAI,OAAOA,QAAQ,KAAK,QAAQ,EAAE;QACnCO,QAAQ,GAAG,IAAI9C,cAAc,CAAC;UAC1BuC,QAAQ,EAAEA,QAAQ;UAClBC,cAAc,EAAE,CAAC,OAAO;QAC5B,CAAC,CAAC;MACN,CAAC,MACI;QACD,MAAM,IAAIO,KAAK,CAAC,yBAAyB,CAAC;MAC9C;MACAF,GAAG,CAACvB,IAAI,CAAC,GAAG,IAAInB,QAAQ,CAAC;QACrB,GAAGe,YAAY;QACfR,GAAG;QACHsC,MAAM,EAAEF;MACZ,CAAC,CAAC;MACF,OAAOD,GAAG;IACd,CAAC,EAAE,CAAC,CAAC,CAAC;IACN,MAAMI,SAAS,GAAG,IAAI5C,iBAAiB,CAAC;MACpC,GAAGc,qBAAqB;MACxBT,GAAG;MACHwC,SAAS,EAAE;IACf,CAAC,CAAC;IACF,OAAO,IAAI1C,gBAAgB,CAAC;MACxB,GAAGS,mBAAmB;MACtBwB,WAAW;MACXE,iBAAiB;MACjB7B,YAAY,EAAEA,YAAY,IAAImC;IAClC,CAAC,CAAC;EACN;EACAE,UAAUA,CAAA,EAAG;IACT,OAAO,oBAAoB;EAC/B;AACJ","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}